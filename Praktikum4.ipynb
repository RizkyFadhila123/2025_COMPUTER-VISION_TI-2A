{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frames, t0 = 0, time.time()\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    frames = frames + 1\n",
    "    if time.time() - t0 >= 1.0 :\n",
    "        cv2.setWindowTitle(\"Preview\", f\"Preview (FPS ~ {frames})\")\n",
    "        frames, t0 = 0, time.time()\n",
    "    cv2.imshow(\"Webcam Preview\", frame)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "# Inisialisasi pengambilan video dari kamera (indeks 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    # Munculkan kesalahan jika kamera tidak dapat dibuka\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi PoseDetector\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1,\n",
    "                        enableSegmentation=False, detectionCon=0.5,\n",
    "                        trackCon=0.5)\n",
    "\n",
    "# Loop utama untuk memproses frame\n",
    "while True:\n",
    "    # Tangkap setiap frame dari webcam\n",
    "    success, img = cap.read()\n",
    " \n",
    "    # Periksa apakah frame berhasil ditangkap\n",
    "    if not success:\n",
    "        print(\"Gagal membaca frame dari kamera.\")\n",
    "        break\n",
    "\n",
    "    # Temukan pose manusia dalam frame\n",
    "    img = detector.findPose(img)\n",
    "\n",
    "    # Temukan landmark (lmList) dan info bounding box (bboxInfo)\n",
    "    lmList, bboxInfo = detector.findPosition(img, draw=True,\n",
    "                                             bboxWithHands=False)\n",
    "\n",
    "    # Periksa apakah ada landmark tubuh yang terdeteksi\n",
    "    if lmList:\n",
    "        # Dapatkan pusat bounding box\n",
    "        center = bboxInfo[\"center\"]\n",
    "\n",
    "        # Gambar lingkaran di pusat bounding box\n",
    "        cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # Hitung jarak antara landmark 11 (Bahu Kiri) dan 15 (Pergelangan Tangan Kiri)\n",
    "        length, img, info = detector.findDistance(lmList[11][0:2],\n",
    "                                                  lmList[15][0:2],\n",
    "                                                  img=img,\n",
    "                                                  color=(255, 0, 0),\n",
    "                                                  scale=10)\n",
    "                                                  \n",
    "        print(\"Jarak: \", length)\n",
    "        # Hitung sudut antara landmark 11 (Bahu Kiri), 13 (Siku Kiri), dan 15 (Pergelangan Tangan Kiri)\n",
    "        angle, img = detector.findAngle(lmList[11][0:2],\n",
    "                                        lmList[13][0:2],\n",
    "                                        lmList[15][0:2],\n",
    "                                        img=img,\n",
    "                                        color=(0, 0, 255),\n",
    "                                        scale=10)\n",
    "\n",
    "        # Periksa apakah sudut mendekati 50 derajat dengan toleransi 10\n",
    "        isCloseAngle50 = detector.angleCheck(myAngle=angle,\n",
    "                                             targetAngle=50,\n",
    "                                             offset=10)\n",
    "\n",
    "        # Cetak hasil pemeriksaan sudut\n",
    "        print(isCloseAngle50)\n",
    "\n",
    "    # Tampilkan frame\n",
    "    cv2.imshow(\"Pose + Angle \", img)\n",
    "\n",
    "    # Keluar jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Bebaskan sumber daya dan tutup jendela\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "\n",
    "# Indeks landmark mata kiri (berdasarkan MediaPipe Face Mesh)\n",
    "# L_TOP (159): atas, L_BOTTOM (145): bawah\n",
    "# L_LEFT (33): kiri, L_RIGHT (133): kanan\n",
    "L_TOP, L_BOTTOM, L_LEFT, L_RIGHT = 159, 145, 33, 133\n",
    "\n",
    "# Fungsi untuk menghitung jarak Euclidean antara dua titik (p1, p2)\n",
    "def dist(p1, p2):\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "# Inisialisasi pengambilan video dari kamera (indeks 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi objek FaceMeshDetector\n",
    "detector = FaceMeshDetector(staticMode=False, maxFaces=2,\n",
    "                            minDetectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "# Variabel untuk menghitung kedipan sederhana\n",
    "blink_count = 0\n",
    "closed_frames = 0\n",
    "CLOSED_FRAMES_THRESHOLD = 3  # Jumlah frame berturut-turut untuk dianggap kedipan\n",
    "EYE_AR_THRESHOLD = 0.20      # Ambang Eye Aspect Ratio (EAR) untuk menilai mata tertutup\n",
    "is_closed = False            # Status apakah mata sudah dihitung sebagai 'tertutup'\n",
    "\n",
    "# Loop utama untuk memproses frame\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "\n",
    "    # Temukan Face Mesh di dalam frame\n",
    "    img, faces = detector.findFaceMesh(img, draw=True)\n",
    "\n",
    "    if faces:\n",
    "        # Ambil data mesh wajah pertama\n",
    "        face = faces[0]  # list of 468 (x,y) landmarks\n",
    "\n",
    "        # Hitung jarak vertikal (v) dan horizontal (h) mata kiri\n",
    "        v = dist(face[L_TOP], face[L_BOTTOM])\n",
    "        h = dist(face[L_LEFT], face[L_RIGHT])\n",
    "\n",
    "        # Hitung Eye Aspect Ratio (EAR)\n",
    "        # Menambahkan 1e-8 untuk menghindari pembagian dengan nol\n",
    "        ear = v / (h + 1e-8)\n",
    "\n",
    "        # Tampilkan nilai EAR pada frame\n",
    "        cv2.putText(img, f\"EAR(L): {ear:.3f}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "        # Logika counter kedipan sederhana:\n",
    "        if ear < EYE_AR_THRESHOLD:\n",
    "            closed_frames += 1\n",
    "\n",
    "            # Jika mata tertutup cukup lama dan belum dihitung sebagai kedipan\n",
    "            if closed_frames >= CLOSED_FRAMES_THRESHOLD and not is_closed:\n",
    "                blink_count += 1\n",
    "                is_closed = True  # Tandai mata sudah dihitung sebagai tertutup/kedipan\n",
    "        else:\n",
    "            # Jika mata terbuka (EAR > EYE_AR_THRESHOLD)\n",
    "            closed_frames = 0\n",
    "            is_closed = False  # Setel ulang status\n",
    "\n",
    "        # Tampilkan jumlah kedipan pada frame\n",
    "        cv2.putText(img, f\"Blink: {blink_count}\", (20, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Tampilkan frame\n",
    "    cv2.imshow(\"FaceMesh + EAR\", img)\n",
    "\n",
    "    # Keluar jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "# Setelah loop berakhir, bebaskan sumber daya dan tutup jendela\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "# Inisialisasi pengambilan video dari kamera (indeks 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi HandDetector\n",
    "detector = HandDetector(staticMode=False, maxHands=1,\n",
    "                        modelComplexity=1, detectionCon=0.5,\n",
    "                        minTrackCon=0.5)\n",
    "\n",
    "# Loop utama untuk memproses frame\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "\n",
    "    # Temukan tangan dalam frame\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True) # flipType untuk mirror UI\n",
    "\n",
    "    if hands:\n",
    "        # Ambil data tangan pertama\n",
    "        hand = hands[0] # dict berisi \"lmList\", \"bbox\", dll.\n",
    "\n",
    "        # Tentukan jari mana yang terangkat\n",
    "        fingers = detector.fingersUp(hand) # list panjang 5 berisi 0/1\n",
    "\n",
    "        # Hitung total jari yang terangkat\n",
    "        count = sum(fingers)\n",
    "\n",
    "        # Tampilkan jumlah jari dan status fingersUp pada frame\n",
    "        cv2.putText(img, f\"Fingers: {count} {fingers}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Tampilkan frame\n",
    "    cv2.imshow(\"Hands + Fingers\", img)\n",
    "\n",
    "    # Keluar jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "# Setelah loop berakhir, bebaskan sumber daya dan tutup jendela\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "# Fungsi untuk menghitung jarak Euclidean antara dua titik (a dan b)\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "# Fungsi utama untuk mengklasifikasikan gesture\n",
    "def classify_gesture(hand):\n",
    "    # hand[\"lmList\"] berisi 21 landmark (x,y,z)\n",
    "    lm = hand[\"lmList\"]\n",
    "    \n",
    "    # Ambil koordinat (x,y) dari landmark kunci\n",
    "    # Landmark: 0=Pergelangan Tangan, 4=Ujung Ibu Jari, 8=Ujung Jari Telunjuk, dst.\n",
    "    wrist = np.array(lm[0][:2])\n",
    "    thumb_tip = np.array(lm[4][:2])\n",
    "    index_tip = np.array(lm[8][:2])\n",
    "    middle_tip = np.array(lm[12][:2])\n",
    "    ring_tip = np.array(lm[16][:2])\n",
    "    pinky_tip = np.array(lm[20][:2])\n",
    "\n",
    "    # Hitung rata-rata jarak relatif semua ujung jari ke pergelangan tangan (wrist)\n",
    "    r_mean = np.mean([dist(index_tip, wrist), dist(middle_tip, wrist),\n",
    "                      dist(ring_tip, wrist), dist(pinky_tip, wrist),\n",
    "                      dist(thumb_tip, wrist)])\n",
    "\n",
    "    # --- Aturan Klasifikasi ---\n",
    "\n",
    "    # 1. Gesture \"OK\" (Ibu jari dan Telunjuk berdekatan)\n",
    "    if dist(thumb_tip, index_tip) < 35: \n",
    "        return \"OK\"\n",
    "\n",
    "    # 2. Gesture \"THUMBS_UP\"\n",
    "    # Syarat: Ibu jari lebih tinggi (koordinat y lebih kecil) dari pergelangan tangan,\n",
    "    # DAN jarak ibu jari ke pergelangan tangan relatif panjang.\n",
    "    if (thumb_tip[1] < wrist[1] - 40) and \\\n",
    "       (dist(thumb_tip, wrist) > 0.8 * dist(index_tip, wrist)):\n",
    "        return \"THUMBS_UP\"\n",
    "\n",
    "    # 3. Gesture \"ROCK\" (Tangan mengepal)\n",
    "    # Syarat: Rata-rata jarak ujung jari ke pergelangan tangan sangat kecil.\n",
    "    if r_mean < 120: \n",
    "        return \"ROCK\"\n",
    "\n",
    "    # 4. Gesture \"PAPER\" (Tangan terbuka)\n",
    "    # Syarat: Rata-rata jarak ujung jari ke pergelangan tangan sangat besar.\n",
    "    if r_mean > 200: \n",
    "        return \"PAPER\"\n",
    "\n",
    "    # 5. Gesture \"SCISSORS\" (Jari Telunjuk dan Jari Tengah terangkat)\n",
    "    # Syarat: Jarak Telunjuk dan Jari Tengah ke pergelangan tangan besar (terangkat),\n",
    "    # DAN jarak Jari Manis dan Kelingking ke pergelangan tangan kecil (terlipat).\n",
    "    if dist(index_tip, wrist) > 180 and dist(middle_tip, wrist) > 180 and \\\n",
    "       dist(ring_tip, wrist) < 160 and dist(pinky_tip, wrist) < 160:\n",
    "        return \"SCISSORS\"\n",
    "\n",
    "    # Jika tidak ada aturan di atas yang terpenuhi\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "# Inisialisasi pengambilan video dari kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "# Inisialisasi HandDetector\n",
    "detector = HandDetector(staticMode=False, maxHands=1,\n",
    "                        modelComplexity=1, detectionCon=0.5,\n",
    "                        minTrackCon=0.5)\n",
    "\n",
    "# Loop utama\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok: break\n",
    "\n",
    "    # Temukan tangan (flipType=True untuk tampilan yang nyaman)\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    if hands:\n",
    "        # Klasifikasikan gesture tangan pertama\n",
    "        label = classify_gesture(hands[0])\n",
    "        \n",
    "        # Tampilkan hasil klasifikasi pada frame\n",
    "        cv2.putText(img, f\"Gesture: {label}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)\n",
    "\n",
    "    # Tampilkan frame\n",
    "    cv2.imshow(\"Hand Gestures (cvzone)\", img)\n",
    "\n",
    "    # Keluar jika tombol 'q' ditekan\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "# Bebaskan sumber daya\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum D6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from collections import deque\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "MODE = \"squat\"   # tekan 'm' untuk toggle ke \"pushup\"\n",
    "KNEE_DOWN, KNEE_UP = 80, 160     # ambang squat (deg)\n",
    "DOWN_R, UP_R     = 0.85, 1.00    # ambang push-up (rasio)\n",
    "SAMPLE_OK        = 4             # minimal frame konsisten sebelum ganti state\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1,\n",
    "                        enableSegmentation=False, detectionCon=0.5,\n",
    "                        trackCon=0.5)\n",
    "\n",
    "count, state = 0, \"up\"\n",
    "debounce = deque(maxlen=6)\n",
    "\n",
    "def ratio_pushup(lm):\n",
    "    # gunakan kiri: 11=shoulderL, 15=wristL, 23=hipL\n",
    "    sh = np.array(lm[11][1:3])\n",
    "    wr = np.array(lm[15][1:3])\n",
    "    hp = np.array(lm[23][1:3])\n",
    "    return np.linalg.norm(sh - wr) / (np.linalg.norm(sh - hp) + 1e-8)\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    img = detector.findPose(img, draw=True)\n",
    "    lmList, _ = detector.findPosition(img, draw=False)  # [(id,x,y,z,vis), ...]\n",
    "    flag = None\n",
    "\n",
    "    if lmList:\n",
    "        if MODE == \"squat\":\n",
    "            # rata-rata sudut lutut kiri & kanan\n",
    "            # angL, _ = detector.findAngle(img, 23, 25, 27, draw=False)\n",
    "            # angR, _ = detector.findAngle(img, 24, 26, 28, draw=False)\n",
    "\n",
    "            angL, img = detector.findAngle(lmList[23][0:2],\n",
    "                                           lmList[25][0:2],\n",
    "                                           lmList[27][0:2],\n",
    "                                           img=img,\n",
    "                                           color=(0, 0, 255),\n",
    "                                           scale=10)\n",
    "            \n",
    "            angR, img = detector.findAngle(lmList[24][0:2],\n",
    "                                           lmList[26][0:2],\n",
    "                                           lmList[28][0:2],\n",
    "                                           img=img,\n",
    "                                           color=(0, 255, 0),\n",
    "                                           scale=10)\n",
    "\n",
    "            ang = (angL + angR) / 2.0\n",
    "            if ang < KNEE_DOWN:\n",
    "                flag = \"down\"\n",
    "            elif ang > KNEE_UP:\n",
    "                flag = \"up\"\n",
    "            cv2.putText(img, f\"Knee: {ang:5.1f}\", (20,70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "        else:\n",
    "            # push-up: rasio (shoulder–wrist)/(shoulder–hip)\n",
    "            r = ratio_pushup(lmList)\n",
    "            if r < DOWN_R:\n",
    "                flag = \"down\"\n",
    "            elif r > UP_R:\n",
    "                flag = \"up\"\n",
    "            cv2.putText(img, f\"Ratio: {r:4.2f}\", (20,70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "\n",
    "        debounce.append(flag)\n",
    "        if debounce.count(\"down\") >= SAMPLE_OK and state == \"up\":\n",
    "            state = \"down\"\n",
    "        if debounce.count(\"up\") >= SAMPLE_OK and state == \"down\":\n",
    "            state = \"up\"; count += 1\n",
    "\n",
    "    cv2.putText(img, f\"Mode: {MODE.upper()}  Count: {count}\", (20,40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
    "    cv2.putText(img, f\"State: {state}\", (20,100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Pose Counter\", img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('m'):\n",
    "        MODE = \"pushup\" if MODE == \"squat\" else \"squat\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
